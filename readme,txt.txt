
CorpusReader.py :
	Parser to read the train and test file. 
	Returns a dataframe with text, position of entities e1 and e2, entities e1 and e2, the relationship between them (relation and edge)
	
FeatureExtractor.py :
	Takes a dataframe (returned by the CorpusReader) and performs the below listed tasks.
		Tokenize each sentence in the dataframe
		Lemmatize entities e1 and e2
		Lemmatize each token generated by the tokenizer
		Assigns a part of speech tag to each token generated by the tokenizer
		Lists sysnsets for each token generated by the tokenizer
		Lists a dependency parse tree
		Lists the ancestors for each entity
		Lists hypernyms, hyponyms, meronyms and holonyms for each entity
	Returns a dataframe with the listed features
	
DataTransform.py :
	Transforms the features from words to vectors
	Returns attributes, models and features (as numpy array) used for further computation
	
utils.py :
	Other helper functions used in decoding or extracting features
	
LSTM.py :
	Deep learning model trained on the features generated
	Returns the model used for prediction
	

Note:
The model was built on python3

Please download the Glove pre-trained word vector file from the link specified in requirements.txt and place it in the working directory.

The train and test file names have been hardcoded in the scripts under the asumption they are present in the working directory.

The model is saved in the working directory by the name 'LSTM' (directory).


